1. Get the application name:
  export APP_NAME=$(kubectl get pods -l "app.kubernetes.io/name={{ include "loadshaper.name" . }},app.kubernetes.io/instance={{ .Release.Name }}" -o jsonpath="{.items[0].metadata.name}")

2. Check the loadshaper status:
  kubectl get pods -l "app.kubernetes.io/name={{ include "loadshaper.name" . }},app.kubernetes.io/instance={{ .Release.Name }}"

3. View loadshaper logs:
  kubectl logs -f $APP_NAME

4. Look for telemetry showing 95th percentile metrics compliance:
  kubectl logs $APP_NAME | grep "\[loadshaper\]" | tail -5

5. Check current configuration:
  kubectl get configmap {{ include "loadshaper.fullname" . }}-config -o yaml

{{- if .Values.persistence.enabled }}
6. Verify metrics storage:
  kubectl get pvc {{ .Values.persistence.existingClaim | default (include "loadshaper.fullname" .) }}
{{- end }}

{{- if and (eq .Values.config.HEALTH_ENABLED "true") .Values.service.metrics.enabled .Values.service.enabled }}
{{- if .Values.serviceMonitor.enabled }}
7. Prometheus metrics endpoint (ServiceMonitor enabled):
  # Metrics are automatically scraped by Prometheus
  # Manual access: kubectl port-forward svc/{{ include "loadshaper.fullname" . }} {{ .Values.config.HEALTH_PORT }}:{{ .Values.config.HEALTH_PORT }}
  # Then visit http://127.0.0.1:{{ .Values.config.HEALTH_PORT }}/metrics
{{- else }}
7. Access metrics endpoint:
  kubectl port-forward svc/{{ include "loadshaper.fullname" . }} {{ .Values.config.HEALTH_PORT }}:{{ .Values.config.HEALTH_PORT }}
  # Then visit http://127.0.0.1:{{ .Values.config.HEALTH_PORT }}/metrics
{{- end }}
{{- end }}

{{- if .Values.service.enabled }}
8. Network generation:
  # loadshaper uses native Python network generator - no external services required
{{- end }}

Oracle Cloud Always Free Compliance:
{{- if contains "e2-micro" .Values.image.tag }}
‚úÖ E2.1.Micro: Targeting {{ .Values.config.CPU_TARGET_PCT }}% CPU, {{ .Values.config.NET_TARGET_PCT }}% of 50 Mbps network
{{- else if contains "a1-flex" .Values.image.tag }}
‚úÖ A1.Flex: Targeting {{ .Values.config.CPU_TARGET_PCT }}% CPU, {{ .Values.config.MEM_TARGET_PCT }}% memory, {{ .Values.config.NET_TARGET_PCT }}% network
{{- else }}
‚úÖ Default: Targeting {{ .Values.config.CPU_TARGET_PCT }}% CPU, {{ .Values.config.MEM_TARGET_PCT }}% memory, {{ .Values.config.NET_TARGET_PCT }}% network
{{- end }}

‚ö†Ô∏è  Important: loadshaper runs at lowest priority (nice 19) and automatically pauses when real workloads need resources.
    Monitor system load to ensure it remains unobtrusive to your applications.

üìä Metrics are stored for 7-day rolling window analysis to match Oracle's reclamation criteria.
    Database cleanup happens automatically - no maintenance required.

{{- if .Values.networkPolicy.enabled }}

üîí SECURITY: NetworkPolicy is enabled for enhanced security.
   Default configuration allows only DNS and same-app pod communication.
   Configure networkPolicy.extraEgress for additional network peers.
{{- end }}

{{- if .Values.security.procHostMountEnabled }}

‚ö†Ô∏è  SECURITY WARNING: hostPath /proc mount is enabled.
   This reduces container isolation and may be blocked by security policies.
   Only use when host-level system monitoring is required.
{{- end }}

{{- if gt (.Values.replicaCount | int) 1 }}

üìù SCALING NOTE: Multiple replicas ({{ .Values.replicaCount }}) require ReadWriteMany storage.
   Current access mode: {{ .Values.persistence.accessModes | first }}
   Consider using ReadWriteMany or separate PVCs for each replica.
{{- end }}

For more information, visit: https://github.com/senomorf/loadshaper